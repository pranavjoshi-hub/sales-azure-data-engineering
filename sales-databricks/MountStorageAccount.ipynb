{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0b71684-c812-47d5-99a7-7ee3a9a4dd5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "configs = {\n",
    "  \"fs.azure.account.auth.type\": \"CustomAccessToken\",\n",
    "  \"fs.azure.account.custom.token.provider.class\": spark.conf.get(\"spark.databricks.passthrough.adls.gen2.tokenProviderClassName\")\n",
    "}\n",
    "\n",
    "# Optionally, you can add <directory-name> to the source URI of your mount point.\n",
    "dbutils.fs.mount(\n",
    "  source = \"abfss://bronze@salesdatalake130324.dfs.core.windows.net/\",\n",
    "  mount_point = \"/mnt/bronze\",\n",
    "  extra_configs = configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "73896946-2955-4af3-97ad-0c08833997cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if the directory is already mounted\n",
    "if len(dbutils.fs.mounts()) > 0:\n",
    "  # Create a DataFrame from the list of mounts\n",
    "  mounts_df = spark.createDataFrame(dbutils.fs.mounts())\n",
    "\n",
    "  # Check if the mountPoint exists in the DataFrame\n",
    "  if mounts_df.filter(mounts_df.mountPoint == \"/mnt/silver\").count() > 0:\n",
    "    # If yes, unmount the directory\n",
    "    dbutils.fs.unmount(\"/mnt/silver\")\n",
    "\n",
    "# Mount the directory\n",
    "dbutils.fs.mount(\n",
    "  source=\"abfss://silver@salesdatalake130324.dfs.core.windows.net/\",\n",
    "  mount_point=\"/mnt/silver\",\n",
    "  extra_configs=configs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465ca1a9-16d2-4392-9e57-3a731c9fa471",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Check if the directory is already mounted\n",
    "if len(dbutils.fs.mounts()) > 0:\n",
    "  # Create a DataFrame from the list of mounts\n",
    "  mounts_df = spark.createDataFrame(dbutils.fs.mounts())\n",
    "\n",
    "  # Check if the mountPoint exists in the DataFrame\n",
    "  if mounts_df.filter(mounts_df.mountPoint == \"/mnt/gold\").count() > 0:\n",
    "    # If yes, unmount the directory\n",
    "    dbutils.fs.unmount(\"/mnt/gold\")\n",
    "\n",
    "# Mount the directory\n",
    "dbutils.fs.mount(\n",
    "  source=\"abfss://gold@salesdatalake130324.dfs.core.windows.net/\",\n",
    "  mount_point=\"/mnt/gold\",\n",
    "  extra_configs=configs\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 63103913849455,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "MountStorageAccount",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
